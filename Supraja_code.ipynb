{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mean \n",
    "import numpy as np\n",
    "import keras \n",
    "from keras.models import Sequential, Model \n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Embedding\n",
    "from keras.layers.merge import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shash\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Accuracy: 0.7350840336134454, Precision: 0.7447690509521512, Recall: 0.7350840336134454\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "def preprocess(row):\n",
    "    text = row['content']\n",
    "    text= text.lower()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = regex.sub(' ', text)\n",
    "    meaningless_words = ['words', 'business wire', 'bwr english', 'copyright', 'businesswire.com',\n",
    "                         'dow jones newswires','djdn english','dow jones institutional news', \n",
    "                         'all rights reserved', 'dow jones company inc', 'pr Newswire',\n",
    "                         'prn english', 'the wall street journal',  'dow jones & company inc',\n",
    "                         'j b4 english']\n",
    "    for words in meaningless_words:\n",
    "        text = text.replace(words, '')\n",
    "    \n",
    "    # picking paragraph containing keywords \n",
    "    text = text.split(\"/n/n\")\n",
    "    text = [para for para in text if \"license\" or 'licensing' in para]\n",
    "    text = ''.join(text)\n",
    "    \n",
    "        \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    text = text.split(' ')\n",
    "    text = [word for word in text if word.isalpha()]\n",
    "    \n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed_text = []\n",
    "    for word in text:\n",
    "        #stemmed_text.append(stemmer.stem(word))\n",
    "        stemmed_text.append(lemmatizer.lemmatize(word))\n",
    "        \n",
    "    text = \" \".join(stemmed_text)\n",
    "    row['content'] = text\n",
    "    return(row)\n",
    "    \n",
    "    \n",
    "    \n",
    "path = r'MASTER_TRAINING.xlsx'\n",
    "licensing_df = pd.read_excel(path)\n",
    "\n",
    "columns = ['content', 'licensing_agreement']\n",
    "data = licensing_df[columns]\n",
    "data = data.apply(preprocess, axis = 1)\n",
    "\n",
    "X = data['content']\n",
    "y = data['licensing_agreement']\n",
    "\n",
    "# Converting to binary\n",
    "#X = X.apply(lambda x:' '.join(f\"{ord(i):08b}\" for i in x))\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(X).toarray()\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test,predictions)\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "print(kf) \n",
    "KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "accuracy=[]\n",
    "precision = []\n",
    "recall = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "    accuracy.append(clf_report['accuracy'])\n",
    "    precision.append(clf_report['weighted avg']['precision'])\n",
    "    recall.append(clf_report['weighted avg']['recall'])\n",
    "print(\"Accuracy: {}, Precision: {}, Recall: {}\".format(mean(accuracy),mean(precision),mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9064039408866995\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "model_logistic = LogisticRegression()\n",
    "model_logistic.fit(X_train, y_train)\n",
    "predictions = model_logistic.predict(X_test)\n",
    "clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "print('Accuracy: ',clf_report['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7672872597314788\n",
      "KFold(n_splits=10, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc = DecisionTreeClassifier()\n",
    "dc_fit = dc.fit(X,y)\n",
    "dc_fit.predict(X_test)\n",
    "clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "accuracy.append(accuracy_score(y_test,predictions))\n",
    "print(mean(accuracy))\n",
    "\n",
    "# Cross Validation\n",
    "cv_adaboost = KFold(n_splits=10)\n",
    "cv_adaboost.get_n_splits(X)\n",
    "print(cv_adaboost) \n",
    "KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "accuracy=[]\n",
    "precision = []\n",
    "recall = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "    accuracy.append(clf_report['accuracy'])\n",
    "    precision.append(clf_report['weighted avg']['precision'])\n",
    "    recall.append(clf_report['weighted avg']['recall'])\n",
    "print(\"Accuracy: {}, Precision: {}, Recall: {}\".format(mean(accuracy),mean(precision),mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Accuracy: 0.8096517917511832, Precision: 0.8127980606879109, Recall: 0.8096517917511832\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)\n",
    "# print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "print(kf) \n",
    "KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "accuracy=[]\n",
    "precision = []\n",
    "recall = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "    accuracy.append(clf_report['accuracy'])\n",
    "    precision.append(clf_report['weighted avg']['precision'])\n",
    "    recall.append(clf_report['weighted avg']['recall'])\n",
    "print(\"Accuracy: {}, Precision: {}, Recall: {}\".format(mean(accuracy),mean(precision),mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8188952697066287\n",
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Accuracy: 0.8096517917511832, Precision: 0.8127980606879109, Recall: 0.8096517917511832\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "clf_adaboost=ab.fit(X,y)\n",
    "clf.predict(X_test)\n",
    "clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "accuracy.append(accuracy_score(y_test,predictions))\n",
    "print(mean(accuracy))\n",
    "\n",
    "# Cross Validation\n",
    "cv_adaboost = KFold(n_splits=10)\n",
    "cv_adaboost.get_n_splits(X)\n",
    "print(cv_adaboost) \n",
    "KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "accuracy=[]\n",
    "precision = []\n",
    "recall = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "    accuracy.append(clf_report['accuracy'])\n",
    "    precision.append(clf_report['weighted avg']['precision'])\n",
    "    recall.append(clf_report['weighted avg']['recall'])\n",
    "print(\"Accuracy: {}, Precision: {}, Recall: {}\".format(mean(accuracy),mean(precision),mean(recall)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
